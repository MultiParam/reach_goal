其实前两份总结，的确是讲了一下机器学习大致的三个步骤，而且也说了一下梯度下降大概是什么样的。

但是忽略了挺多东西的，比如什么是 `train/test data`，什么是 `过拟合欠拟合` 等等。而概念的搞懂对于后头的实践还是有帮助的，所以我想想到什么细节就补充一下。

首先我们针对一个问题。

1. 选择了一个函数集合(未定参数的模型)。$f(w) = wx$
2. 确定 `loss function`。$L(w) = \sum(\hat{y} - wx)^2$
3. 找到最好的函数(梯度下降)

而梯度下降的步骤之前也大致写了，也不赘述，如下是参数 $w$ 的梯度公式：
$$
L(w) = 2\sum(y - wx)(-x)
$$
那么这个 $x, y$ 从哪而来。就是从`train data` ，也就是训练集而来。而且是多个 `samlpe`，越多的 `samlpe` 越能接近普遍情况：
$$
X_{train} =\begin{bmatrix}
122\\
22\\
33\\
...
\end{bmatrix}
Y_{train} =\begin{bmatrix}
1.24\\
2.355\\
3.3334\\
...
\end{bmatrix}
$$
训练数据可以是图像像素，可以是一个表格提取的数据，总之训练数据会被代入梯度公式，一步一步训练，得到一个形状确定的模型。
$$
y = 0.1x\\
(w = 0.1)\\
$$
当然，得到模型后并不是可以拍手称快了。我们以上做的只是针对 `train data` ，模型在其上的表现可能是不错的，但是我们需要模型就是为了做预测，或者说发现一个潜在的规律。

也就是我们关心模型的 **泛化** 能力。

那么我们现在的模型，是否准确需要如何衡量？

那就给另外一组数据，来检测一下模型预测的如何，而这组数据就叫做 `test data`，测试集。例如我们有一组`test data`
$$
X_{test} =\begin{bmatrix}
12\\
22\\
33\\
...
\end{bmatrix}
Y_{test} =\begin{bmatrix}
1.2\\
2.3\\
3.34\\
...
\end{bmatrix}
$$
将这些数据代入训练好的模型，利用定义好的 `loss function` 来衡量模型面对未知数据的准确性。

在理论上，我们会根据模型在 `train\test data`  上的表现组合得到如下结果：

|           | train bad                | train good            |
| --------- | ------------------------ | --------------------- |
| test good | ~~train bad, test good~~ | train good, test good |
| test bad  | train bad, test bad      | train good, test bad  |

我们的目标：`train good, test good`，也就是在训练集上效果好，也要在测试集上效果好。但是天总不是随人愿的，会出现 `train good, test bad` 和 `train bad, test bad`两种情况。(至于表格中被划线的情况，因为个人认为在 `train data` 上表现不好，更不用谈在测试集上表现更好了。当然这一点我也不是特别确定，欢迎指正。)

 