[TOC]

这个东西是根据李宏毅机器学习 2017 与配套 PPT 进行学习。

**当然， 这个全靠印象写，如果有缺漏，就第二次查缺补漏。**

除开对这个课程的总览介绍，第一篇便是
从```Regression``` ，也就是回归开始讲起，也是利用回归作为切入点，来了解机器学习的一些概念的关键步骤。

对于回归的概念，抄一下百度：
```
在统计学中，回归分析(regression analysis)指的是确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。
```

举几个例子，例如根据路况值、周围车辆数量值、障碍物数量等变量，作为 input 输入到一个 function，然后输出车辆需要偏移的角度：
$$
f(路况,车辆,障碍物) = \theta
$$
概念先大概这么多。在 ```Regression``` 这门课中，李宏毅老师是以机器学习的三步骤讲课的。所以我就大致归纳一下，机器学习三步骤。

# 这里应该加一个训练的概念



# step 1 定义一个函数集合

## 函数集合

**函数集合**其实就是一个类型函数的集合，它有一个更为大众所知的名字 —— **模型**。

举个例子就知道什么意思了。还是上文提到的预测车的偏移角度，假设有一个函数集合，通过路况 ```road```，周围车辆 ```car``` ，障碍物数量 ```bar```  这三个值，我们可以这么假设：
$$
y = b + w_{road}x_{road} + w_{car}x_{car} + w_{bar}x_{bar}
$$
这就是定义了一个函数集合，为什么呢？因为它代表了所有这种形状的函数：
$$
f1: y = 0.1 + 0.3x_{road} + 0.4x_{car} + 0.5x_{bar}\\
f2: y = 0.2 + 0.4x_{road} + 0.3x_{car} + 0.5x_{bar}\\
f3: y = 0.3 + 0.5x_{road} + 0.6x_{car} + 0.7x_{bar}\\
...
$$
所以当我们想利用机器学习来解决一个问题的时候，先需要找一个这样的函数集合。

通过训练模型(后头会说)，找到一组 ```w```, ```b```(或是别的参数) ，使得函数预测最准，便是训练得到的一个**确定的**模型，一个函数。

## 线性回归模型

知道函数集合的概念，就可以知道我们熟知的线性回归模型其实也就是一个函数集合：
$$
y = b + \sum w_ix_i\\
$$
再拿上文预测车辆偏移角度的例子对比一下就知道了，就是一个线性回归模型。
$$
{y = b + w_{road}x_{road} + w_{car}x_{car} + w_{bar}x_{bar}}
$$

通过上式，我们可以得到一些信息。这个模型(函数) 的输入是这样的：
$$
X_1 = [x_{road1}, x_{car1}, x_{bar1}]\\
X_2 = [x_{road2}, x_{car2}, x_{bar2}]\\
....
$$

那么 $X_1$ 便是一个 ```sample```，也就是一个样本数据，这个样本数据就是代入这个函数的 ```input```。而 $x_{road1}, x_{car1}, x_{bar1}$ 这些是一个样本的特征 ```feature``` 值。

如果不太理解的话，就理解成一个学生成绩管理系统，一个学生的数据里头有数学、语文、英语的成绩，而这些成绩是 ```feature```，而这些 ```feature``` 组成了一个 ```sample```。

而对应的 $w_{road},w_{car},w_{bar}$ 是对应特征的权重。

所以训练的过程便是将许多的 ```sample``` 代入一个函数集合，找到一组 ```w```, ```b```(或是别的参数) ，使得函数预测最准，从而找到一个**确定**的函数或称为模型。



# step 2 找一个 loss function

~~还是拿上文的预测车辆偏移角度举例，我们通过训练(也就是代入多组 ```sample```)，~~

我们已经定义了一个函数集合，**假定**训练出了一个模型，那么如何衡量这个模型的好坏？所以我们需要一个 ```loss function``` 来衡量。```loss function``` 通常是衡量模型预测结果与真实结果的差异，从而反映了模型的好坏。

我们以线性回归模型为例。
$$
f(w,b) = b + \sum w_ix_i \\
$$
我们完全可以使用如下式子来当做 ```loss function``` $L(w,b)$
$$
L(w, b) = \frac{\sum_{i=0}^n(\hat{y^n} - f(w,b))^2}{2n} (n = 1,2,3 ...)\\
$$

$n$ 为 ```sample``` 总数。

# step 3 找到最好的 function

当然第二步有个前提，

有了一个 ```loss function``` ，可以去 ```function set```中找到一个表现最好的 ```function```。

如何做到？思路便是 ``loss`` 越小，便说明这个 ```function``` 表现越好。

还是以线性回归模型的 ```loss function``` 为例：
$$
L(w, b) = \frac{\sum_{i=0}^n(\hat{y^n} - f(w,b))^2}{2n} (n = 1,2,3 ...)\\
$$
所以我们需要在一堆满足 $L(w, b)$ 的  $w, b$ 中，找一组 $w^*, b^*$，使得 $L(w, b)$ 最小。而下式就是表达这个意思。
$$
w^*,b^* = \arg{\underset{w,b}{min}}L(w,b)
$$
所以训练的过程便是将许多的 ```sample``` 代入一个函数集合，找一组 $w^*, b^*$， 使得 $L(w, b)$ 最小，从而找到一个确定的函数。

# 2020.07.20 - 22

这就是暂时总结的机器学习三步骤。因为更侧重三步骤的串联，所以其中其实省略了一些概念。

下一个周期 (2020.07.23 - 25) 的目标便是：

1. 补全一些概念。
2. 梯度下降的粗浅解释。